{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ng0sECDlfMuS",
        "outputId": "656f37ec-b4a3-4704-fa09-0c2d7c4d3078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import kerastuner as kt\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "train_data_file =  'train_data.txt'\n",
        "\n",
        "# Loading the training data\n",
        "train_data = pd.read_csv(train_data_file, sep=\":::\", header=None, names=[\"ID\", \"Title\", \"Genre\", \"Description\"], engine='python')\n",
        "\n",
        "# Preprocessing\n",
        "train_data['cleaned_description'] = train_data['Description'].str.lower().str.replace(\"[^a-z0-9 ]\", \"\", regex=True)\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['genre_label'] = label_encoder.fit_transform(train_data['Genre'].str.strip())\n",
        "\n",
        "# Tokenization and Padding\n",
        "max_num_words = 5000\n",
        "max_sequence_length = 150\n",
        "tokenizer = Tokenizer(num_words=max_num_words)\n",
        "tokenizer.fit_on_texts(train_data['cleaned_description'])\n",
        "sequences = tokenizer.texts_to_sequences(train_data['cleaned_description'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Splitting the data\n",
        "test_val_size = 0.4\n",
        "test_size = 0.5\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(padded_sequences, train_data['genre_label'], test_size=test_val_size, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=test_size, random_state=42)\n",
        "\n",
        "# Model building function for hyperparameter tuning\n",
        "def build_cnn_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size, output_dim=hp.Int('embedding_dim', min_value=32, max_value=128, step=32), input_length=max_sequence_length))\n",
        "    model.add(Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Choice('kernel_size', values=[3, 5, 7]), activation='relu'))\n",
        "    model.add(GlobalMaxPooling1D())\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.compile(optimizer=Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Hyperparameter tuning\n",
        "tuner = kt.RandomSearch(build_cnn_model, objective='val_accuracy', max_trials=10, executions_per_trial=1, directory='cnn_tuning', project_name='keras_tuner_cnn')\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_val, y_val), callbacks=[EarlyStopping(monitor='val_accuracy', patience=2)])\n",
        "\n",
        "# The best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.fit(X_train, y_train, batch_size=32, epochs=5, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluation\n",
        "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0PjPOr9fRLt",
        "outputId": "0d547f14-96b0-4308-8966-5c5887d91983"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 04m 59s]\n",
            "val_accuracy: 0.4372406303882599\n",
            "\n",
            "Best val_accuracy So Far: 0.5417320132255554\n",
            "Total elapsed time: 01h 12m 29s\n",
            "Epoch 1/5\n",
            "1017/1017 [==============================] - 184s 180ms/step - loss: 0.8948 - accuracy: 0.7449 - val_loss: 1.6976 - val_accuracy: 0.5368\n",
            "Epoch 2/5\n",
            "1017/1017 [==============================] - 173s 170ms/step - loss: 0.5812 - accuracy: 0.8467 - val_loss: 1.8509 - val_accuracy: 0.5344\n",
            "Epoch 3/5\n",
            "1017/1017 [==============================] - 173s 170ms/step - loss: 0.3175 - accuracy: 0.9297 - val_loss: 2.0542 - val_accuracy: 0.5204\n",
            "Epoch 4/5\n",
            "1017/1017 [==============================] - 185s 182ms/step - loss: 0.1439 - accuracy: 0.9794 - val_loss: 2.3171 - val_accuracy: 0.5201\n",
            "Epoch 5/5\n",
            "1017/1017 [==============================] - 170s 167ms/step - loss: 0.0570 - accuracy: 0.9966 - val_loss: 2.5582 - val_accuracy: 0.5168\n",
            "339/339 [==============================] - 3s 8ms/step - loss: 2.6070 - accuracy: 0.5107\n",
            "Test Accuracy: 0.5106520056724548\n"
          ]
        }
      ]
    }
  ]
}